{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', None)\n",
    "# Make the request to the API\n",
    "req = urllib.request.Request('https://livescore-api.com/api-client/scores/history.json?secret=dRjupfSdWvLvhbBgdglu3iY0GWZYVYF8&key=Z1F4hMWtXoYZiZYG&package_id=4&page=8000')\n",
    "response = urllib.request.urlopen(req)\n",
    "# Read the response and convert it from JSON to a Python dictionary\n",
    "data = json.loads(response.read())\n",
    "# Assuming the relevant data is in a key named 'data' (you will need to adjust this based on the actual structure of the JSON response)\n",
    "# Convert the dictionary to a pandas DataFrame\n",
    "df = pd.DataFrame(data['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.DataFrame()\n",
    "# Loop through pages 4000 to 14000\n",
    "for page in range(14300, 14604):  # Adjust the range as needed\n",
    "    print(f\"Processing page: {page}\")\n",
    "    # Construct the request URL for the current page\n",
    "    url = f'https://livescore-api.com/api-client/scores/history.json?secret=dRjupfSdWvLvhbBgdglu3iY0GWZYVYF8&key=Z1F4hMWtXoYZiZYG&package_id=4&page={page}'\n",
    "    # Make the request to the API\n",
    "    req = urllib.request.Request(url)\n",
    "    response = urllib.request.urlopen(req)\n",
    "    # Read the response and convert it from JSON to a Python dictionary\n",
    "    data = json.loads(response.read())\n",
    "    df = pd.DataFrame(data['data'])\n",
    "    df_match = pd.json_normalize(df['match'])\n",
    "    all_data = pd.concat([all_data, df_match], ignore_index=True)\n",
    "# Display the shape of the DataFrame to see how many rows of data were collected\n",
    "all_data.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['home_name', 'score', 'ht_score', 'away_name', 'id']\n",
    "df_selected = all_data[selected_columns]\n",
    "df_selected.to_csv('history_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty list to store match statistics\n",
    "match_stats_list = []\n",
    "\n",
    "# Loop through each match id in the sliced DataFrame\n",
    "for index, row in df_selected.iterrows():\n",
    "    print(f\"Processing id: {row['id']}\")\n",
    "    match_id = row['id']\n",
    "    url = f'https://livescore-api.com/api-client/matches/stats.json?match_id={match_id}&key=Z1F4hMWtXoYZiZYG&secret=dRjupfSdWvLvhbBgdglu3iY0GWZYVYF8'\n",
    "\n",
    "    # Make the request to the API\n",
    "    req = urllib.request.Request(url)\n",
    "    response = urllib.request.urlopen(req)\n",
    "    data = json.loads(response.read())\n",
    "\n",
    "    # Prepare a dictionary to hold the match statistics\n",
    "    stats = data['data']\n",
    "    match_dict = {\n",
    "        'home_name': row['home_name'],\n",
    "        'score': row['score'],\n",
    "        'ht_score': row['ht_score'],\n",
    "        'away_name': row['away_name'],\n",
    "        'id': row['id']\n",
    "    }\n",
    "\n",
    "    # Loop through each statistic and split the values for home and away teams\n",
    "    if isinstance(stats, dict):\n",
    "        for stat, value in stats.items():\n",
    "            if value is not None and ':' in value:\n",
    "                home_value, away_value = value.split(':')\n",
    "                match_dict[f'{stat}_home'] = home_value\n",
    "                match_dict[f'{stat}_away'] = away_value\n",
    "            else:\n",
    "                match_dict[stat] = value  # For stats not split between home and away\n",
    "\n",
    "    match_stats_list.append(match_dict)\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df_match_stats = pd.DataFrame(match_stats_list)\n",
    "df_match_stats\n",
    "df_match_stats.to_csv('match_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Danh sách các cột ban đầu\n",
    "cols = df_match_stats.columns\n",
    "# Lọc ra các cột có chứa \"_away\", \"_home\", và các cột cần giữ\n",
    "cols_with_home_away = [col for col in cols if \"_away\" in col or \"_home\" in col or col in [\"home_name\", \"score\",\"ht_score\",\"away_name\", \"id\"]]\n",
    "\n",
    "# Tạo dataframe mới với các cột đã lọc\n",
    "df = df_match_stats[cols_with_home_away]\n",
    "df.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = ['home_name', 'score', 'ht_score', 'away_name', 'id']\n",
    "\n",
    "# Columns to check for zeros\n",
    "check_columns = df.columns.difference(exclude_columns)\n",
    "\n",
    "# Calculate the sum across the check_columns for each row\n",
    "# Replace 0.0 with np.nan and then use dropna to remove rows with all zeros in check_columns\n",
    "df = df.replace({col: {0.0: np.nan} for col in check_columns}).dropna(how='all', subset=check_columns)\n",
    "\n",
    "# Replace np.nan back to 0.0 if needed\n",
    "df.fillna(0.0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_columns = ['home_name', 'score', 'ht_score', 'away_name', 'id']\n",
    "\n",
    "# Columns to check for zeros\n",
    "check_columns = df.columns.difference(exclude_columns)\n",
    "\n",
    "# Calculate the sum across the check_columns for each row\n",
    "# Replace 0.0 with np.nan and then use dropna to remove rows with all zeros in check_columns\n",
    "df = df.replace({col: {0.0: np.nan} for col in check_columns}).dropna(how='all', subset=check_columns)\n",
    "\n",
    "# Replace np.nan back to 0.0 if needed\n",
    "df.fillna(0.0, inplace=True)\n",
    "# Tách cột 'score' thành 'score_home' và 'score_away'\n",
    "df[['score_home', 'score_away']] = df['score'].str.split(' - ', expand=True)\n",
    "df[['ht_score_home', 'ht_score_away']] = df['ht_score'].str.split(' - ', expand=True)\n",
    "\n",
    "# Chuyển đổi kiểu dữ liệu của 'score_home' và 'score_away' thành số nguyên\n",
    "df['score_home'] = df['score_home'].astype(int)\n",
    "df['score_away'] = df['score_away'].astype(int)\n",
    "\n",
    "# Xóa cột 'score'\n",
    "df = df.drop(columns=['score'])\n",
    "df = df.drop(columns=['ht_score'])\n",
    "df = df.drop(columns=['id'])\n",
    "columns_to_exclude = ['home_name', 'away_name', 'ht_score_home', 'ht_score_away','score_home', 'score_away']\n",
    "columns_to_divide = df.columns.difference(columns_to_exclude)\n",
    "df[columns_to_divide] = df[columns_to_divide] / 2\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data_processed.csv', index=False)  "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
