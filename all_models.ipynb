{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import thư viện cần thiết**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'EPL23-24.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Đọc file dữ liệu và chuyển vào dataframe\u001b[39;00m\n\u001b[0;32m      2\u001b[0m df_saved_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPL23-24.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m df_ml \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_saved_name\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Đọc file CSV vào dataframe df_ml\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\huyho\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huyho\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\huyho\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\huyho\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\huyho\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'EPL23-24.csv'"
     ]
    }
   ],
   "source": [
    "# Đọc file dữ liệu và chuyển vào dataframe\n",
    "df_saved_name = 'EPL23-24.csv'\n",
    "df_ml = pd.read_csv(df_saved_name)  # Đọc file CSV vào dataframe df_ml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đọc file dữ liệu và chuyển vào dataframe\n",
    "df_saved_name = 'football_data.csv'\n",
    "df_ml = pd.read_csv(df_saved_name)  # Đọc file CSV vào dataframe df_ml\n",
    "\n",
    "# Điền giá trị 0 vào các ô bị thiếu\n",
    "df_ml = df_ml.fillna(0)  # Điền giá trị 0 vào các ô trống trong dataframe df_ml\n",
    "\n",
    "# Chọn các cột cần giữ lại\n",
    "columns_to_keep = ['Time', 'Div', 'Date', 'HomeTeam', 'AwayTeam', 'FTR', 'Referee', 'HTR']\n",
    "df_keep = df_ml[columns_to_keep]  # Tạo dataframe df_keep chứa các cột đã chọn\n",
    "\n",
    "# Chọn các cột cần chuẩn hóa\n",
    "columns_to_scale = [col for col in df_ml.columns if col not in columns_to_keep]\n",
    "df_scale = df_ml[columns_to_scale]  # Tạo dataframe df_scale chứa các cột cần chuẩn hóa\n",
    "\n",
    "# Chuẩn hóa các cột đã chọn\n",
    "scaled_np = preprocessing.scale(df_scale)  # Chuẩn hóa dữ liệu trong df_scale\n",
    "scaled_df = pd.DataFrame(scaled_np, columns=df_scale.columns)  # Tạo dataframe mới từ dữ liệu đã chuẩn hóa\n",
    "\n",
    "# Kết hợp các cột đã giữ lại và các cột đã chuẩn hóa\n",
    "data = pd.concat([df_keep, scaled_df], axis=1)  # Kết hợp df_keep và scaled_df\n",
    "\n",
    "# Loại bỏ các cột không cần thiết\n",
    "data = data.drop(['Div', 'Referee', 'HTR', 'Time', 'Date'], axis=1)  # Loại bỏ các cột không cần thiết\n",
    "\n",
    "# Chọn các cột mong muốn\n",
    "desired_columns = ['HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR']\n",
    "data = data.loc[:, desired_columns]  # Tạo dataframe data chỉ chứa các cột mong muốn\n",
    "\n",
    "# Đọc file dữ liệu mùa giải trước và chuyển vào dataframe\n",
    "last_season = 'last_season.csv'\n",
    "last_season = pd.read_csv(last_season)  # Đọc file CSV vào dataframe last_season\n",
    "\n",
    "# Điền giá trị 0 vào các ô bị thiếu\n",
    "last_season = last_season.fillna(0)  # Điền giá trị 0 vào các ô trống trong dataframe last_season\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rolling_averages_home(df, team, n=5):\n",
    "    # Columns to exclude from rolling average calculation\n",
    "    exclude_columns = ['FTR', 'HomeTeam', 'AwayTeam']\n",
    "    \n",
    "    # Filter DataFrame for rows where the specified team is either the HomeTeam or AwayTeam\n",
    "    team_df = df[(df['HomeTeam'] == team)]\n",
    "    \n",
    "    # Columns to calculate rolling averages for\n",
    "    columns_to_average = team_df.columns.difference(exclude_columns)\n",
    "    # Calculate rolling averages for the specified columns\n",
    "    rolling_stats = team_df[columns_to_average].rolling(window=n).mean().shift(1)\n",
    "    # Concatenate the team information with the rolling statistics\n",
    "    rolling_stats = pd.concat([team_df[exclude_columns], rolling_stats], axis=1)\n",
    "    \n",
    "    return rolling_stats\n",
    "def calculate_rolling_averages_away(df, team, n=10):\n",
    "    # Columns to exclude from rolling average calculation\n",
    "    exclude_columns = ['FTR', 'HomeTeam', 'AwayTeam']\n",
    "    \n",
    "    # Filter DataFrame for rows where the specified team is either the HomeTeam or AwayTeam\n",
    "    team_df = df[(df['AwayTeam'] == team)]\n",
    "    \n",
    "    # Columns to calculate rolling averages for\n",
    "    columns_to_average = team_df.columns.difference(exclude_columns)\n",
    "    # Calculate rolling averages for the specified columns\n",
    "    rolling_stats = team_df[columns_to_average].rolling(window=n).mean().shift(1)\n",
    "    # Concatenate the team information with the rolling statistics\n",
    "    rolling_stats = pd.concat([team_df[exclude_columns], rolling_stats], axis=1)\n",
    "    \n",
    "    return rolling_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_win = last_season.groupby('HomeTeam')['FTR'].apply(lambda x: (x == 'H').mean())\n",
    "home_draw = last_season.groupby('HomeTeam')['FTR'].apply(lambda x: (x == 'D').mean())\n",
    "away_win = last_season.groupby('AwayTeam')['FTR'].apply(lambda x: (x == 'A').mean())\n",
    "away_draw = last_season.groupby('AwayTeam')['FTR'].apply(lambda x: (x == 'D').mean())\n",
    "\n",
    "# Tạo DataFrame mới từ các Series trên\n",
    "last_season_stats = pd.DataFrame({\n",
    "    'LSHW': home_win,\n",
    "    'LSHD': home_draw,\n",
    "    'LSAW': away_win,\n",
    "    'LSAD': away_draw\n",
    "}).reset_index()\n",
    "\n",
    "# Đổi tên cột 'index' thành 'Team' để dễ dàng merge\n",
    "last_season_stats.rename(columns={'index': 'Team'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Prepare the dataset\n",
    "def prepare_dataset_away(data, teams):\n",
    "    all_data = []\n",
    "    for team in teams:\n",
    "        rolling_stats = calculate_rolling_averages_away(data, team)\n",
    "        all_data.append(rolling_stats)\n",
    "    return pd.concat(all_data)\n",
    "def prepare_dataset_home(data, teams):\n",
    "    all_data = []\n",
    "    for team in teams:\n",
    "        rolling_stats = calculate_rolling_averages_home(data, team)\n",
    "        all_data.append(rolling_stats)\n",
    "    return pd.concat(all_data)\n",
    "# List of teams\n",
    "teams = data['HomeTeam'].unique()\n",
    "\n",
    "# Prepare the dataset\n",
    "prepare_dataset_away = prepare_dataset_away(data, teams)\n",
    "prepare_dataset_away = prepare_dataset_away.fillna(0)\n",
    "prepare_dataset_home = prepare_dataset_home(data, teams)\n",
    "prepare_dataset_home = prepare_dataset_home.fillna(0)\n",
    "prepare_dataset_away['FTR'] = prepare_dataset_away['FTR'].astype('category').cat.codes\n",
    "prepare_dataset_home['FTR'] = prepare_dataset_home['FTR'].astype('category').cat.codes\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Giả sử bạn đã có hai dataframe prepare_dataset_away và prepare_dataset_home\n",
    "\n",
    "# Merge hai dataframe\n",
    "merged_df = pd.merge(prepare_dataset_away, prepare_dataset_home, on=['FTR', 'HomeTeam', 'AwayTeam'], suffixes=('_away', '_home'))\n",
    "\n",
    "# Chọn các cột cần thiết\n",
    "columns_away = ['AC_away', 'AF_away', 'AR_away', 'AS_away', 'AST_away', 'AY_away', 'FTAG_away']\n",
    "columns_home = ['FTHG_home', 'HC_home', 'HF_home', 'HR_home', 'HS_home', 'HST_home', 'HY_home']\n",
    "columns_to_group = ['FTR', 'HomeTeam', 'AwayTeam'] + columns_away + columns_home\n",
    "\n",
    "# Tạo dataframe mới và nhóm theo 'FTR', 'HomeTeam', 'AwayTeam'\n",
    "new_df = merged_df[columns_to_group].groupby(['FTR', 'HomeTeam', 'AwayTeam']).mean().reset_index()\n",
    "\n",
    "current_df_copy = new_df.copy()\n",
    "\n",
    "# Tiếp theo, merge `current_df_copy` với `last_season_df` để lấy thông số cho đội nhà\n",
    "current_df_copy = current_df_copy.merge(last_season_stats[['Team', 'LSHW', 'LSHD']], left_on='HomeTeam', right_on='Team', how='left')\n",
    "current_df_copy.rename(columns={'LSHW': 'LSHW_home', 'LSHD': 'LSHD_home'}, inplace=True)\n",
    "\n",
    "# Sau đó, merge `current_df_copy` với `last_season_df` một lần nữa để lấy thông số cho đội khách\n",
    "current_df_copy = current_df_copy.merge(last_season_stats[['Team', 'LSAW', 'LSAD']], left_on='AwayTeam', right_on='Team', how='left', suffixes=('', '_away'))\n",
    "current_df_copy.rename(columns={'LSAW': 'LSAW_away', 'LSAD': 'LSAD_away'}, inplace=True)\n",
    "\n",
    "# Loại bỏ các cột 'Team' và 'Team_away' không cần thiết\n",
    "current_df_copy.drop(['Team', 'Team_away'], axis=1, inplace=True)\n",
    "\n",
    "# Tạo một bản đồ thay thế cho các đội đặc biệt\n",
    "special_teams_map = {\n",
    "    'Burnley': 'Leicester',\n",
    "    'Sheffield United': 'Leeds',\n",
    "    'Luton': 'Southampton'\n",
    "}\n",
    "\n",
    "# Thay thế thông số của các đội đặc biệt bằng thông số của đội tương ứng\n",
    "for team, replace_with in special_teams_map.items():\n",
    "    # Lấy thông số của đội thay thế\n",
    "    replace_stats = last_season_stats.loc[last_season_stats['Team'] == replace_with, ['LSHW', 'LSHD', 'LSAW', 'LSAD']].iloc[0]\n",
    "    \n",
    "    # Cập nhật thông số cho đội cần thay thế trong DataFrame hiện tại\n",
    "    current_df_copy.loc[current_df_copy['HomeTeam'] == team, ['LSHW_home', 'LSHD_home']] = replace_stats[['LSHW', 'LSHD']].values\n",
    "    current_df_copy.loc[current_df_copy['AwayTeam'] == team, ['LSAW_away', 'LSAD_away']] = replace_stats[['LSAW', 'LSAD']].values\n",
    "\n",
    "# Encode categorical variables\n",
    "current_df_copy['HomeTeam'] = current_df_copy['HomeTeam'].astype('category').cat.codes\n",
    "current_df_copy['AwayTeam'] = current_df_copy['AwayTeam'].astype('category').cat.codes\n",
    "# Define features and target variable\n",
    "X = current_df_copy.drop('FTR', axis=1)\n",
    "y = current_df_copy['FTR']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best parameters found:  {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.61        33\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.64      0.75      0.69        36\n",
      "\n",
      "    accuracy                           0.61        76\n",
      "   macro avg       0.43      0.44      0.44        76\n",
      "weighted avg       0.59      0.61      0.59        76\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  2 12]\n",
      " [ 4  0  3]\n",
      " [ 6  3 27]]\n",
      "Accuracy Score:\n",
      "0.6052631578947368\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 10],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize the classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize the GridSearchCV with error handling\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, error_score=np.nan)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Predict with the best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 252 candidates, totalling 1260 fits\n",
      "Best parameters found:  {'metric': 'manhattan', 'n_neighbors': 41, 'p': 1, 'weights': 'uniform'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.21      0.30        33\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.51      0.86      0.64        36\n",
      "\n",
      "    accuracy                           0.50        76\n",
      "   macro avg       0.34      0.36      0.31        76\n",
      "weighted avg       0.46      0.50      0.43        76\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  0 26]\n",
      " [ 3  0  4]\n",
      " [ 4  1 31]]\n",
      "Accuracy Score:\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_neighbors': [1,3, 5, 7, 9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Predict with the best model\n",
    "best_knn = grid_search.best_estimator_\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix \n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy Score:\") \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
      "Best parameters found:  {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.55      0.60        33\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.66      0.75      0.70        36\n",
      "\n",
      "    accuracy                           0.59        76\n",
      "   macro avg       0.44      0.43      0.43        76\n",
      "weighted avg       0.60      0.59      0.59        76\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18  5 10]\n",
      " [ 3  0  4]\n",
      " [ 6  3 27]]\n",
      "Accuracy Score:\n",
      "0.5921052631578947\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid for GridSearchCV specific to Decision Tree\n",
    "# Define the parameter grid for GridSearchCV specific to Decision Tree\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]  # Removed 'auto' from the options\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Predict with the best model\n",
    "best_dt = grid_search.best_estimator_\n",
    "y_pred = best_dt.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'var_smoothing': 0.02848035868435802}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.30      0.40        33\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.53      0.86      0.65        36\n",
      "\n",
      "    accuracy                           0.54        76\n",
      "   macro avg       0.37      0.39      0.35        76\n",
      "weighted avg       0.50      0.54      0.48        76\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0 23]\n",
      " [ 2  0  5]\n",
      " [ 5  0 31]]\n",
      "Accuracy Score:\n",
      "0.5394736842105263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huyho\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\huyho\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\huyho\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "# Initialize the Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=gnb, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Predict with the best model\n",
    "best_gnb = grid_search.best_estimator_\n",
    "y_pred = best_gnb.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siêu tham số tốt nhất:  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "Báo cáo phân loại:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.45      0.53        33\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.59      0.83      0.69        36\n",
      "\n",
      "    accuracy                           0.59        76\n",
      "   macro avg       0.40      0.43      0.41        76\n",
      "weighted avg       0.55      0.59      0.56        76\n",
      "\n",
      "Ma trận nhầm lẫn:\n",
      "[[15  1 17]\n",
      " [ 3  0  4]\n",
      " [ 6  0 30]]\n",
      "Độ chính xác:\n",
      "0.5921052631578947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Định nghĩa tham số grid cho GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10], \n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# Khởi tạo mô hình SVM \n",
    "svm = SVC()\n",
    "\n",
    "# Khởi tạo GridSearchCV với scoring phù hợp cho bài toán phân loại đa lớp\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Huấn luyện mô hình với GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Lấy siêu tham số tốt nhất\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Siêu tham số tốt nhất: \", best_params)\n",
    "\n",
    "# Đánh giá mô hình với siêu tham số tốt nhất\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_pred = best_svm.predict(X_test)\n",
    "\n",
    "# In ra báo cáo phân loại\n",
    "print(\"Báo cáo phân loại:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# In ra ma trận nhầm lẫn\n",
    "print(\"Ma trận nhầm lẫn:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# In ra độ chính xác\n",
    "print(\"Độ chính xác:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
