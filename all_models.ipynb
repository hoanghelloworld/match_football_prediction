{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_model_eval import pred_proba_plot, plot_cross_val_confusion_matrix, plot_learning_curve\n",
    "from data_processing import scale_df\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, cross_val_predict\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "df_saved_name = 'football_data.csv'\n",
    "df_ml = pd.read_csv(df_saved_name)\n",
    "df_ml=df_ml.fillna(0)\n",
    "columns_to_keep = ['Time','Div','Date','HomeTeam','AwayTeam','FTR','Referee','HTR']\n",
    "df_keep = df_ml[columns_to_keep]\n",
    "columns_to_scale = [col for col in df_ml.columns if col not in columns_to_keep]\n",
    "df_scale = df_ml[columns_to_scale]\n",
    "scaled_np = preprocessing.scale(df_scale)\n",
    "scaled_df = pd.DataFrame(scaled_np, columns=df_scale.columns)\n",
    "data = pd.concat([df_keep, scaled_df], axis=1)\n",
    "data=data.drop(['Div','Referee','HTR','Time','Date'],axis=1)\n",
    "desired_columns = ['HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'FTR', 'HS', 'AS', 'HST', 'AST', 'HF', 'AF', 'HC', 'AC', 'HY', 'AY', 'HR', 'AR']\n",
    "data = data.loc[:, desired_columns]\n",
    "\n",
    "last_season = 'last_season.csv'\n",
    "last_season = pd.read_csv(last_season)\n",
    "last_season=last_season.fillna(0)\n",
    "\n",
    "\n",
    "def calculate_rolling_averages_home(df, team, n=5):\n",
    "    # Columns to exclude from rolling average calculation\n",
    "    exclude_columns = ['FTR', 'HomeTeam', 'AwayTeam']\n",
    "    \n",
    "    # Filter DataFrame for rows where the specified team is either the HomeTeam or AwayTeam\n",
    "    team_df = df[(df['HomeTeam'] == team)]\n",
    "    \n",
    "    # Columns to calculate rolling averages for\n",
    "    columns_to_average = team_df.columns.difference(exclude_columns)\n",
    "    # Calculate rolling averages for the specified columns\n",
    "    rolling_stats = team_df[columns_to_average].rolling(window=n).mean().shift(1)\n",
    "    # Concatenate the team information with the rolling statistics\n",
    "    rolling_stats = pd.concat([team_df[exclude_columns], rolling_stats], axis=1)\n",
    "    \n",
    "    return rolling_stats\n",
    "def calculate_rolling_averages_away(df, team, n=10):\n",
    "    # Columns to exclude from rolling average calculation\n",
    "    exclude_columns = ['FTR', 'HomeTeam', 'AwayTeam']\n",
    "    \n",
    "    # Filter DataFrame for rows where the specified team is either the HomeTeam or AwayTeam\n",
    "    team_df = df[(df['AwayTeam'] == team)]\n",
    "    \n",
    "    # Columns to calculate rolling averages for\n",
    "    columns_to_average = team_df.columns.difference(exclude_columns)\n",
    "    # Calculate rolling averages for the specified columns\n",
    "    rolling_stats = team_df[columns_to_average].rolling(window=n).mean().shift(1)\n",
    "    # Concatenate the team information with the rolling statistics\n",
    "    rolling_stats = pd.concat([team_df[exclude_columns], rolling_stats], axis=1)\n",
    "    \n",
    "    return rolling_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_win = last_season.groupby('HomeTeam')['FTR'].apply(lambda x: (x == 'H').mean())\n",
    "home_draw = last_season.groupby('HomeTeam')['FTR'].apply(lambda x: (x == 'D').mean())\n",
    "away_win = last_season.groupby('AwayTeam')['FTR'].apply(lambda x: (x == 'A').mean())\n",
    "away_draw = last_season.groupby('AwayTeam')['FTR'].apply(lambda x: (x == 'D').mean())\n",
    "\n",
    "# Tạo DataFrame mới từ các Series trên\n",
    "last_season_stats = pd.DataFrame({\n",
    "    'LSHW': home_win,\n",
    "    'LSHD': home_draw,\n",
    "    'LSAW': away_win,\n",
    "    'LSAD': away_draw\n",
    "}).reset_index()\n",
    "\n",
    "# Đổi tên cột 'index' thành 'Team' để dễ dàng merge\n",
    "last_season_stats.rename(columns={'index': 'Team'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Prepare the dataset\n",
    "def prepare_dataset_away(data, teams):\n",
    "    all_data = []\n",
    "    for team in teams:\n",
    "        rolling_stats = calculate_rolling_averages_away(data, team)\n",
    "        all_data.append(rolling_stats)\n",
    "    return pd.concat(all_data)\n",
    "def prepare_dataset_home(data, teams):\n",
    "    all_data = []\n",
    "    for team in teams:\n",
    "        rolling_stats = calculate_rolling_averages_home(data, team)\n",
    "        all_data.append(rolling_stats)\n",
    "    return pd.concat(all_data)\n",
    "# List of teams\n",
    "teams = data['HomeTeam'].unique()\n",
    "\n",
    "# Prepare the dataset\n",
    "prepare_dataset_away = prepare_dataset_away(data, teams)\n",
    "prepare_dataset_away = prepare_dataset_away.fillna(0)\n",
    "prepare_dataset_home = prepare_dataset_home(data, teams)\n",
    "prepare_dataset_home = prepare_dataset_home.fillna(0)\n",
    "prepare_dataset_away['FTR'] = prepare_dataset_away['FTR'].astype('category').cat.codes\n",
    "prepare_dataset_home['FTR'] = prepare_dataset_home['FTR'].astype('category').cat.codes\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Giả sử bạn đã có hai dataframe prepare_dataset_away và prepare_dataset_home\n",
    "\n",
    "# Merge hai dataframe\n",
    "merged_df = pd.merge(prepare_dataset_away, prepare_dataset_home, on=['FTR', 'HomeTeam', 'AwayTeam'], suffixes=('_away', '_home'))\n",
    "\n",
    "# Chọn các cột cần thiết\n",
    "columns_away = ['AC_away', 'AF_away', 'AR_away', 'AS_away', 'AST_away', 'AY_away', 'FTAG_away']\n",
    "columns_home = ['FTHG_home', 'HC_home', 'HF_home', 'HR_home', 'HS_home', 'HST_home', 'HY_home']\n",
    "columns_to_group = ['FTR', 'HomeTeam', 'AwayTeam'] + columns_away + columns_home\n",
    "\n",
    "# Tạo dataframe mới và nhóm theo 'FTR', 'HomeTeam', 'AwayTeam'\n",
    "new_df = merged_df[columns_to_group].groupby(['FTR', 'HomeTeam', 'AwayTeam']).mean().reset_index()\n",
    "\n",
    "current_df_copy = new_df.copy()\n",
    "\n",
    "# Tiếp theo, merge `current_df_copy` với `last_season_df` để lấy thông số cho đội nhà\n",
    "current_df_copy = current_df_copy.merge(last_season_stats[['Team', 'LSHW', 'LSHD']], left_on='HomeTeam', right_on='Team', how='left')\n",
    "current_df_copy.rename(columns={'LSHW': 'LSHW_home', 'LSHD': 'LSHD_home'}, inplace=True)\n",
    "\n",
    "# Sau đó, merge `current_df_copy` với `last_season_df` một lần nữa để lấy thông số cho đội khách\n",
    "current_df_copy = current_df_copy.merge(last_season_stats[['Team', 'LSAW', 'LSAD']], left_on='AwayTeam', right_on='Team', how='left', suffixes=('', '_away'))\n",
    "current_df_copy.rename(columns={'LSAW': 'LSAW_away', 'LSAD': 'LSAD_away'}, inplace=True)\n",
    "\n",
    "# Loại bỏ các cột 'Team' và 'Team_away' không cần thiết\n",
    "current_df_copy.drop(['Team', 'Team_away'], axis=1, inplace=True)\n",
    "\n",
    "# Tạo một bản đồ thay thế cho các đội đặc biệt\n",
    "special_teams_map = {\n",
    "    'Burnley': 'Leicester',\n",
    "    'Sheffield United': 'Leeds',\n",
    "    'Luton': 'Southampton'\n",
    "}\n",
    "\n",
    "# Thay thế thông số của các đội đặc biệt bằng thông số của đội tương ứng\n",
    "for team, replace_with in special_teams_map.items():\n",
    "    # Lấy thông số của đội thay thế\n",
    "    replace_stats = last_season_stats.loc[last_season_stats['Team'] == replace_with, ['LSHW', 'LSHD', 'LSAW', 'LSAD']].iloc[0]\n",
    "    \n",
    "    # Cập nhật thông số cho đội cần thay thế trong DataFrame hiện tại\n",
    "    current_df_copy.loc[current_df_copy['HomeTeam'] == team, ['LSHW_home', 'LSHD_home']] = replace_stats[['LSHW', 'LSHD']].values\n",
    "    current_df_copy.loc[current_df_copy['AwayTeam'] == team, ['LSAW_away', 'LSAD_away']] = replace_stats[['LSAW', 'LSAD']].values\n",
    "\n",
    "# Encode categorical variables\n",
    "current_df_copy['HomeTeam'] = current_df_copy['HomeTeam'].astype('category').cat.codes\n",
    "current_df_copy['AwayTeam'] = current_df_copy['AwayTeam'].astype('category').cat.codes\n",
    "# Define features and target variable\n",
    "X = current_df_copy.drop('FTR', axis=1)\n",
    "y = current_df_copy['FTR']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Best parameters found:  {'bootstrap': True, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.58      0.61        33\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.64      0.75      0.69        36\n",
      "\n",
      "    accuracy                           0.61        76\n",
      "   macro avg       0.43      0.44      0.44        76\n",
      "weighted avg       0.59      0.61      0.59        76\n",
      "\n",
      "Confusion Matrix:\n",
      "[[19  2 12]\n",
      " [ 4  0  3]\n",
      " [ 6  3 27]]\n",
      "Accuracy Score:\n",
      "0.6052631578947368\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 10],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Initialize the classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize the GridSearchCV with error handling\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2, error_score=np.nan)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Predict with the best model\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 252 candidates, totalling 1260 fits\n",
      "Best parameters found:  {'metric': 'manhattan', 'n_neighbors': 41, 'p': 1, 'weights': 'uniform'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.21      0.30        33\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.51      0.86      0.64        36\n",
      "\n",
      "    accuracy                           0.50        76\n",
      "   macro avg       0.34      0.36      0.31        76\n",
      "weighted avg       0.46      0.50      0.43        76\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  0 26]\n",
      " [ 3  0  4]\n",
      " [ 4  1 31]]\n",
      "Accuracy Score:\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_neighbors': [1,3, 5, 7, 9,11,13,15,17,19,21,23,25,27,29,31,33,35,37,39,41],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan', 'minkowski'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "\n",
    "# Initialize the KNN classifier\n",
    "knn = KNeighborsClassifier()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=knn, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Predict with the best model\n",
    "best_knn = grid_search.best_estimator_\n",
    "y_pred = best_knn.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix \n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy Score:\") \n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 270 candidates, totalling 1350 fits\n",
      "Best parameters found:  {'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.55      0.60        33\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.66      0.75      0.70        36\n",
      "\n",
      "    accuracy                           0.59        76\n",
      "   macro avg       0.44      0.43      0.43        76\n",
      "weighted avg       0.60      0.59      0.59        76\n",
      "\n",
      "Confusion Matrix:\n",
      "[[18  5 10]\n",
      " [ 3  0  4]\n",
      " [ 6  3 27]]\n",
      "Accuracy Score:\n",
      "0.5921052631578947\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid for GridSearchCV specific to Decision Tree\n",
    "# Define the parameter grid for GridSearchCV specific to Decision Tree\n",
    "param_grid = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]  # Removed 'auto' from the options\n",
    "}\n",
    "\n",
    "# Initialize the Decision Tree classifier\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=dt, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Predict with the best model\n",
    "best_dt = grid_search.best_estimator_\n",
    "y_pred = best_dt.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best parameters found:  {'var_smoothing': 0.02848035868435802}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.30      0.40        33\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.53      0.86      0.65        36\n",
      "\n",
      "    accuracy                           0.54        76\n",
      "   macro avg       0.37      0.39      0.35        76\n",
      "weighted avg       0.50      0.54      0.48        76\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0 23]\n",
      " [ 2  0  5]\n",
      " [ 5  0 31]]\n",
      "Accuracy Score:\n",
      "0.5394736842105263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\huyho\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\huyho\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\huyho\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "# Initialize the Gaussian Naive Bayes classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'var_smoothing': np.logspace(0,-9, num=100)\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=gnb, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy', verbose=2)\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best parameters found: \", best_params)\n",
    "\n",
    "# Predict with the best model\n",
    "best_gnb = grid_search.best_estimator_\n",
    "y_pred = best_gnb.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Print the confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Print the accuracy score\n",
    "print(\"Accuracy Score:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Siêu tham số tốt nhất:  {'C': 1, 'gamma': 0.0001, 'kernel': 'linear'}\n",
      "Báo cáo phân loại:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.45      0.53        33\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.59      0.83      0.69        36\n",
      "\n",
      "    accuracy                           0.59        76\n",
      "   macro avg       0.40      0.43      0.41        76\n",
      "weighted avg       0.55      0.59      0.56        76\n",
      "\n",
      "Ma trận nhầm lẫn:\n",
      "[[15  1 17]\n",
      " [ 3  0  4]\n",
      " [ 6  0 30]]\n",
      "Độ chính xác:\n",
      "0.5921052631578947\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Định nghĩa tham số grid cho GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10], \n",
    "    'gamma': [0.0001, 0.001, 0.01, 0.1],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "\n",
    "# Khởi tạo mô hình SVM \n",
    "svm = SVC()\n",
    "\n",
    "# Khởi tạo GridSearchCV với scoring phù hợp cho bài toán phân loại đa lớp\n",
    "grid_search = GridSearchCV(estimator=svm, param_grid=param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Huấn luyện mô hình với GridSearchCV\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Lấy siêu tham số tốt nhất\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Siêu tham số tốt nhất: \", best_params)\n",
    "\n",
    "# Đánh giá mô hình với siêu tham số tốt nhất\n",
    "best_svm = grid_search.best_estimator_\n",
    "y_pred = best_svm.predict(X_test)\n",
    "\n",
    "# In ra báo cáo phân loại\n",
    "print(\"Báo cáo phân loại:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# In ra ma trận nhầm lẫn\n",
    "print(\"Ma trận nhầm lẫn:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# In ra độ chính xác\n",
    "print(\"Độ chính xác:\")\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
